created: 20241126073635184
creator: zhoujiagen@gmail.com
modified: 20241126101407824
modifier: zhoujiagen@gmail.com
tags: [[Machine Learning]] NLP 2024-09-15
title: NLP
type: text/vnd.tiddlywiki

---

tags:

* MachineLearning
* NLP
* number headings: auto, first-level 1, max 6, 1.1
* date: 2024-09-15

---

|            |                                                                                                                                        |
| ---------- | -------------------------------------------------------------------------------------------------------------------------------------- |
| æ—¶é—´         | å†…å®¹                                                                                                                                     |
| 2019-04-14 | reading The Illustrated Word2vec: [ext[https://jalammar.github.io/illustrated-word2vec/]] |
| 2019-04-16 | æ·»åŠ word2vecç¬”è®°å’Œå®è·µword2vec.ipynb                                                                                                          |
| 2019-04-19 | reading A Primer on Neural Network Models for Natural Language Processing<br><br>until feature representation                          |
| 2020-07-15 | æ·»åŠ NLTKèµ„æº                                                                                                                               |

! 1 Tips for Recapture

<!-- å¸®åŠ©é‡æ¸©çš„è¿‡ç¨‹æ€»ç»“. -->

# Step 1
# Step 2
# Step 3
# Step 4

! 2 æœ¯è¯­

<!-- è®°å½•é˜…è¯»è¿‡ç¨‹ä¸­å‡ºç°çš„å…³é”®å­—åŠå…¶ç®€å•çš„è§£é‡Š. -->

Stemming: è¯å¹²è¿˜åŸ
Lemmatization: è¯å½¢å½’å¹¶
lemma:
Morphplogical Normalization: è¯å½¢è¿˜åŸ
sequence-to-sequence (seq2seq) neural networks
Part-Of-Speech(POS) Tagging: è¯æ€§æ ‡æ³¨

CBOW: continuous bag-of-words
skip-gram models

Lexis: è¯æ±‡å­¦

Semantics: è¯­ä¹‰å­¦
lexemes: è¯ä½
content words: å®è¯
function words: è™šè¯
utterance: è¯´è¯æ–¹å¼
signify: è¡¨ç¤º...çš„æ„æ€
symbol/referent: ç¬¦å·/æŒ‡ç¤ºç‰©
name/thing/sense: åç§°/äº‹ç‰©/å«ä¹‰
mental perception: å¿ƒç†çŸ¥è§‰
mental images: å¿ƒç†æ„è±¡
semantic range: è¯­ä¹‰åŒº
semantic field: è¯­ä¹‰åœº
hyponymy: è¯ä¹‰ä¹‹é—´çš„ä¸Šä¸‹æ–‡å…³ç³»
componential analysis: (è¯­ä¹‰)æˆåˆ†åˆ†æ
synonym: åŒä¹‰è¯
antonym: åä¹‰è¯

collocation: è¯çš„æ­é…
idiom: ä¹ è¯­
homonymy: åŒéŸ³å¼‚ä¹‰
polysemy: ä¸€è¯å¤šä¹‰
pragmatics: è¯­ç”¨å­¦
discourse analysis: è¯­ç¯‡åˆ†æ

Phonetics: è¯­éŸ³å­¦

Phonology: éŸ³ä½å­¦

Morphology: å½¢æ€å­¦

Syntax: å¥æ³•å­¦

! 3 ä»‹ç»

<!-- æè¿°è½¯ä»¶çš„æ¥æºã€ç‰¹æ€§ã€è§£å†³çš„å…³é”®æ€§é—®é¢˜ç­‰. -->

! 4 åŠ¨æœº

<!-- æè¿°é˜…è¯»è½¯ä»¶æºç çš„åŠ¨æœº, è¦è¾¾åˆ°ä»€ä¹ˆç›®çš„ç­‰. -->

! 5 ç³»ç»Ÿç»“æ„

<!-- æè¿°è½¯ä»¶çš„ç³»ç»Ÿç»“æ„, æ ¸å¿ƒå’Œè¾…åŠ©ç»„ä»¶çš„ç»“æ„; ç³»ç»Ÿè¾ƒå¤æ‚æ—¶ç»†åˆ†å±•ç¤º. -->

! 6 ä½¿ç”¨

<!-- è®°å½•è½¯ä»¶å¦‚ä½•ä½¿ç”¨. -->

!! 6.1 NLTK

* NLTK Corpora: http://www.nltk.org/nltk\_data/

!! 6.2 Lemmatization

State-of-the-art Multilingual Lemmatization: An analysis of state-of-the-art lemmatizers that work for tens of languages
https://towardsdatascience.com/state-of-the-art-multilingual-lemmatization-f303e8ff1a8

!! 6.3 word2vec

GloVe vector trained on Wikipedia
GloVe: Global Vectors for Word Representation
https://nlp.stanford.edu/projects/glove/

Using the Gensim library in python, we can add and subtract word vectors, and it would find the most similar words to the resulting vector. The image shows a list of the most similar words, each with its cosine similarity.
gensim: Topic Modelling for Humans
https://radimrehurek.com/gensim/index.html
models.word2vec â€“ Word2vec embeddings
https://radimrehurek.com/gensim/models/word2vec.html
scripts.glove2word2vec â€“ Convert glove format to word2vec
https://radimrehurek.com/gensim/scripts/glove2word2vec.html

Skipgram with Negative Sampling (SGNS)
[img[./images/image1.png]]

è®­ç»ƒè¿‡ç¨‹

(1) æ•°æ®é›†å’Œæ¨¡å‹
[img[./images/image3.png]]
[img[./images/image4.png]]

(2) æ¨¡å‹å‚æ•°è°ƒæ•´

input â¦ output: å‘é‡ç‚¹ç§¯(dot product)

sigmoidåœ¨çº¿è®¡ç®—å™¨: https://keisan.casio.com/
sigmoid(0.2)=0.5498339973124779085592
sigmoid(-1.11)=0.247870888560429841227
sigmoid(0.74)=0.6769958562385229973568

We can now use this error score to adjust the embeddings of not, thou, aaron, and taco so that the next time we make this calculation, the result would be closer to the target scores.
''TODO(zhoujiagen) å¦‚ä½•adjustçš„?''
[img[./images/image2.png]]

!! 6.4 Morden deep learning techniques

! 7 æ•°æ®ç»“æ„å’Œç®—æ³•

<!-- æè¿°è½¯ä»¶ä¸­é‡è¦çš„æ•°æ®ç»“æ„å’Œç®—æ³•, æ”¯æ’‘è¿‡ç¨‹éƒ¨åˆ†çš„è®°å½•. -->

! 8 è¿‡ç¨‹

<!-- æè¿°è½¯ä»¶ä¸­é‡è¦çš„è¿‡ç¨‹æ€§å†…å®¹, ä¾‹å¦‚æœåŠ¡å™¨çš„å¯åŠ¨ã€æœåŠ¡å™¨å“åº”å®¢æˆ·ç«¯è¯·æ±‚ã€æœåŠ¡å™¨èƒŒæ™¯æ´»åŠ¨ç­‰. -->

! 9 æ–‡çŒ®å¼•ç”¨

<!-- è®°å½•è½¯ä»¶ç›¸å…³å’Œè¿›ä¸€æ­¥é˜…è¯»èµ„æ–™: æ–‡çŒ®ã€ç½‘é¡µé“¾æ¥ç­‰. -->

å…¥é—¨:

* A Primer on Neural Network Models for Natural Language Processing
* è¯åµŒå…¥:
* Recurrent neural network based language model
* Distributed Representations of Words and Phrases and their Compositionality
* æ·±åº¦å­¦ä¹ æ–¹æ³•:
* Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank

! 10 å…¶ä»–å¤‡æ³¨

[[awesome-nlp: ğŸ“– A curated list of resources dedicated to Natural Language Processing (NLP)|https://github.com/keon/awesome-nlp]]

! 11 Courses

[[Stanford CS 224N - Natural Language Processing with Deep Learning|https://web.stanford.edu/class/cs224n/]]

! 12 TODO

* [[Natural Language Processing with PyTorch|https://www.oreilly.com/library/view/natural-language-processing/9781491978221/]]
* [ext[https://www.kdnuggets.com/2023/06/5-free-books-natural-language-processing-read-2023.html]]
* [ext[https://www.guvi.in/blog/best-natural-language-processing-books/]]
* [ext[https://www.analyticsvidhya.com/blog/2023/07/nlp-books-every-data-scientist-must-read/]]

! 13 Applications

Large Language Model

* [[Ollama|https://ollama.com/]]
** [[starcoder2|https://ollama.com/library/starcoder2]]

! 14 WordNet

* [[wngloss(7WN)|https://wordnet.princeton.edu/documentation/wngloss7wn]]: WordNetç³»ç»Ÿä¸­ä½¿ç”¨çš„æœ¯è¯­.
* [[How to get domain of words using WordNet in Python?|https://stackoverflow.com/questions/21902411/how-to-get-domain-of-words-using-wordnet-in-python]]: [[WordNet Domain resource|http://wndomains.fbk.eu/]]

! 15 VerbNet

* [[VerbNet Homepage|https://verbs.colorado.edu/verbnet/]]
* [[A Class-Based Verb Lexicon, by Martha Palmer|https://verbs.colorado.edu/~mpalmer/projects/verbnet.html]]
